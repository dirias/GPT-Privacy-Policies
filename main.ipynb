{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ------------------------------------->\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 68s 21s/step - loss: 2.7273 - accuracy: 0.6889 - val_loss: 5.3875 - val_accuracy: 0.7826\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 59s 20s/step - loss: 2.9423 - accuracy: 0.6889 - val_loss: 3.0154 - val_accuracy: 0.7826\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 57s 19s/step - loss: 2.5117 - accuracy: 0.8444 - val_loss: 3.6853 - val_accuracy: 0.7826\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 59s 20s/step - loss: 2.3750 - accuracy: 0.8444 - val_loss: 2.4303 - val_accuracy: 0.7826\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 57s 19s/step - loss: 1.3964 - accuracy: 0.8444 - val_loss: 0.7810 - val_accuracy: 0.7826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d8a21f00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Custom Classes\n",
    "from utils import generate_summary, generate_input_text\n",
    "from SummarizerBERT import SummarizerBERT\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 2e-5\n",
    "VOCAB_SIZE = 30522  # This is for BERT base\n",
    "EMBED_SIZE = 768\n",
    "MAX_LENGTH = 512\n",
    "NUM_LAYERS = 12\n",
    "HEADS = 12\n",
    "FORWARD_EXPANSION = 4\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# Define key terms/phrases\n",
    "KEY_TERMS = [\"data collection\", \"third-party\", \"cookies\", \"disclosure\", \"security\", \"rights\", \"retention\"]\n",
    "\n",
    "# 1. Data Preparation\n",
    "# Split data into training and validation\n",
    "texts_train, texts_val, labels_train, labels_val = generate_input_text(KEY_TERMS)\n",
    "\n",
    "# 2. Tokenization\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_encodings = tokenizer(texts_train, truncation=True, padding='max_length', max_length=MAX_LENGTH, return_tensors=\"tf\")\n",
    "val_encodings = tokenizer(texts_val, truncation=True, padding='max_length', max_length=MAX_LENGTH, return_tensors=\"tf\")\n",
    "\n",
    "# 3. Model Compilation\n",
    "model = SummarizerBERT(VOCAB_SIZE, EMBED_SIZE, NUM_LAYERS, HEADS, FORWARD_EXPANSION, DROPOUT, MAX_LENGTH)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# 4. Training\n",
    "print('Fitting ------------------------------------->')\n",
    "model.fit([train_encodings['input_ids'], train_encodings['attention_mask']], np.array(labels_train),\n",
    "        validation_data=([val_encodings['input_ids'], val_encodings['attention_mask']], np.array(labels_val)),\n",
    "        batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2c28d2050>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2c28d2050>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2c299d300>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2c299d300>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2c299df60>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2c299df60>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2c29809d0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2c29809d0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x31aaedf90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x31aaedf90>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x31aaf4880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x31aaf4880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x31aaf7130>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x31aaf7130>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2d8a01a20>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2d8a01a20>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2d8a03f70>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2d8a03f70>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2d8a0abc0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2d8a0abc0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2d8a194b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2d8a194b0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2d8a1bd60>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x2d8a1bd60>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "We are always available to address any questions, concerns, or suggestions you may have.\n",
      "\n",
      "Thank you for placing your trust in Company XYZ. Together, let's create a digital experience that respects and celebrates privacy.\n",
      "\n",
      "Feel free to reach out to our dedicated support team, who will be more than happy to assist you.\n",
      "\n",
      "It is always advisable to review this policy periodically, as we may update it to reflect changes in legal or operational requirements.\n"
     ]
    }
   ],
   "source": [
    "policy_text = \"\"\"\n",
    "At Company XYZ, we are deeply committed to safeguarding the privacy and personal information of our users. \n",
    "We recognize the trust you place in us when you share your data, and we consider it our topmost responsibility to ensure its security.\n",
    "This Privacy Policy has been designed to inform our users about the practices we employ concerning data collection, handling, and storage. \n",
    "The primary aim of collecting data is to continuously enhance our services, making them tailored to our user's preferences. We believe that by understanding our users better, we can offer more intuitive features and ensure a seamless user experience.\n",
    "It's essential for our users to note that the data we collect is stored with top-tier encryption protocols. We have partnered with leading cybersecurity firms to ensure that the infrastructure hosting user data remains impenetrable to unauthorized access. Moreover, Company XYZ firmly stands by the principle that user data is sacred and, under no circumstances, is shared, sold, or leased to third-party companies, advertisers, or data brokers.\n",
    "By choosing to use our services, you inherently consent to the practices described in this policy. \n",
    "It is always advisable to review this policy periodically, as we may update it to reflect changes in legal or operational requirements. \n",
    "We are always available to address any questions, concerns, or suggestions you may have. \n",
    "Feel free to reach out to our dedicated support team, who will be more than happy to assist you.\n",
    "Thank you for placing your trust in Company XYZ. Together, let's create a digital experience that respects and celebrates privacy.\n",
    "\"\"\"\n",
    "summary = generate_summary(policy_text, model, tokenizer, MAX_LENGTH, summary_length=4)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
